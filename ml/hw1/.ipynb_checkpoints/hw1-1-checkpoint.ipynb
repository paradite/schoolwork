{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework #1 - The Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This skeleton file is provided for HW#1 only.  You are expected to modify it for use in this and other homeworks for the course.)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the README section for A0000000X's submission.\n",
    "(For group submissions [when applicable], simply concatenate the student matric numbers in lexicographical order separated by a '-' (dash); e.g., A0000000X-A0000001Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Notes about this assignment \n",
    "\n",
    "Place your comments or requests here for the CS3244 staff to read.  Discuss your architecture or experiments in general.  A paragraph or two is usually sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files included with this submission\n",
    "\n",
    "List the files in your submission here and provide a short 1 line description of each file.  Make sure your submission's files are named and formatted correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "# Plotting with style! \n",
    "import seaborn as sb \n",
    "\n",
    "# Size the plot appropriately for online display\n",
    "pl.rcParams['figure.figsize'] = (12.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the random number generator first, in case we need results that are replicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(3244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "We also add a bias column of 1s for training data x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def add_bias_column(x):\n",
    "    return np.insert(x, 0, 1, axis=1)\n",
    "\n",
    "input_dimension = 20\n",
    "weight_dimension = input_dimension + 1 # add bias\n",
    "training_data = pd.read_table('hw1-train.dat', delim_whitespace=True, header=None)\n",
    "x_input = training_data.values[:,:input_dimension]\n",
    "y_input = training_data.values[:,input_dimension]\n",
    "N = len(x_input)\n",
    "x_input = add_bias_column(x_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR\n",
    "\n",
    "`learn_batch` function is used for batch selection.\n",
    "`learn_single_point` function is used for deterministic single point selection.\n",
    "Both use `lr` function as the underlying learning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch learning with 2333 iterations and eta of 0.05\n",
      "batch learning with 2333 iterations and eta of 0.005\n",
      "single point learning with 2333 iterations and eta of 0.05\n",
      "single point learning with 2333 iterations and eta of 0.005\n"
     ]
    }
   ],
   "source": [
    "def compute_single_point_gradient(xi, yi, current_w):\n",
    "    numerator = yi * xi\n",
    "    denominator = 1 + math.exp(yi * current_w.dot(xi))\n",
    "    return (numerator / denominator)\n",
    "\n",
    "def compute_ave_gradient(xn, yn, current_w):\n",
    "    gradient_sum = np.zeros(weight_dimension)\n",
    "    for idx in range(N):\n",
    "        gradient_sum += compute_single_point_gradient(xn[idx], yn[idx], current_w)\n",
    "    ave_gradient = (-1 / N) * gradient_sum\n",
    "    return ave_gradient\n",
    "\n",
    "def compute_new_weight(ave_gradient, current_w, eta):\n",
    "    return current_w + eta * (ave_gradient * (-1))\n",
    "\n",
    "def lr(current_w, eta, use_single_point = False, iteration_number = 0):\n",
    "    if use_single_point:\n",
    "        idx = iteration_number % N\n",
    "        gradient = -compute_single_point_gradient(x_input[idx], y_input[idx], current_w)\n",
    "    else:\n",
    "        gradient = compute_ave_gradient(x_input, y_input, current_w)\n",
    "    return compute_new_weight(gradient, current_w, eta)\n",
    "\n",
    "def compute_single_in_sample_error(xi, yi, current_w):\n",
    "    return np.log(1 + math.exp((-yi) * current_w.dot(xi)))\n",
    "\n",
    "def compute_ave_in_sample_error(xn, yn, current_w):\n",
    "    err_sum = 0\n",
    "    for idx in range(N):\n",
    "        err_sum += compute_single_in_sample_error(xn[idx], yn[idx], current_w)\n",
    "    err_ave = (1 / N) * err_sum\n",
    "    return err_ave\n",
    "\n",
    "def learn_batch(iterations, eta):\n",
    "    print('batch learning with ' + str(iterations) + ' iterations and eta of ' + str(eta))\n",
    "    w = np.zeros(weight_dimension)\n",
    "    for x in range(iterations):\n",
    "        w = lr(w, eta, False)\n",
    "    return w\n",
    "\n",
    "def learn_single_point(iterations, eta):\n",
    "    print('single point learning with ' + str(iterations) + ' iterations and eta of ' + str(eta))\n",
    "    w = np.zeros(weight_dimension)\n",
    "    for x in range(iterations):\n",
    "        w = lr(w, eta, True, x)\n",
    "    return w\n",
    "\n",
    "w1 = learn_batch(2333, 0.05)\n",
    "w2 = learn_batch(2333, 0.005)\n",
    "w3 = learn_single_point(2333, 0.05)\n",
    "w4 = learn_single_point(2333, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing_data = pd.read_table('hw1-test.dat', delim_whitespace=True, header=None)\n",
    "x_test = testing_data.values[:,:input_dimension]\n",
    "x_test = add_bias_column(x_test)\n",
    "y_test = testing_data.values[:,input_dimension]\n",
    "N_test = len(x_test)\n",
    "\n",
    "def check_weight_against_test(weight, test_xi, test_yi):\n",
    "    dot_product = weight.dot(test_xi)\n",
    "    # print(dot_product)\n",
    "    h_x = math.exp(dot_product) / (1 + math.exp(dot_product))\n",
    "    prediction = 1 if (h_x >= 0.5) else -1\n",
    "    # print(prediction == test_yi)\n",
    "    return (prediction == test_yi)\n",
    "\n",
    "def compute_out_of_sample_error(weight):\n",
    "    err_sum = 0\n",
    "    for idx in range(N_test):\n",
    "        if(check_weight_against_test(weight, x_test[idx], y_test[idx]) != True):\n",
    "            err_sum += 1\n",
    "    err_ave = (1 / N_test) * err_sum\n",
    "    return err_ave\n",
    "\n",
    "def print_result(weight):\n",
    "    print('weight:')\n",
    "    print(weight.tolist())\n",
    "    # print('in-sample error')\n",
    "    # print(compute_ave_in_sample_error(x_input, y_input, weight))\n",
    "    print('out-sample error:')\n",
    "    print(compute_out_of_sample_error(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for η = 0.05 for T = 2333 (batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11619989953257741,\n",
       " -0.6230638861458145,\n",
       " 0.8305469786461498,\n",
       " -1.0934973403011155,\n",
       " 0.05572273780420706,\n",
       " -1.1139138777344821,\n",
       " -0.01296554708163877,\n",
       " 1.1124953425644475,\n",
       " -0.8158812303486359,\n",
       " 0.4309260722643113,\n",
       " 1.4234615491768567,\n",
       " 0.2768854305700301,\n",
       " -0.8809569714738535,\n",
       " -0.5974162096293618,\n",
       " 0.8570422509145481,\n",
       " 1.1536100733824346,\n",
       " 1.3039896671074884,\n",
       " -1.3480710066622437,\n",
       " 1.3424348786513611,\n",
       " -0.6163682044354374,\n",
       " -1.1006430680003119]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18433333333333332"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_out_of_sample_error(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for η = 0.005 for T = 2333 (batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26366666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26366666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_out_of_sample_error(w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for η = 0.05 for T = 2333 (single point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w3.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_out_of_sample_error(w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for η = 0.005 for T = 2333 (single point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w4.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_out_of_sample_error(w4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay Questions\n",
    "\n",
    "_You may choose to do the essay questions here in the .ipynb notebook, but you are welcomed to use a word processor instead and write your solutions there instead (and convert it into .pdf format).  If you do that, please ensure to delete this section._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. [LFD Exercise 1.2] Suppose that we use a perceptron to detect spam messages. Let's say that each email messages represented by the frequency of occurrence of keywords, and the output is +1 if the message is considered spam.\n",
    "\n",
    "    1. Can you think of some keywords that will end up with a large positive weight into perceptron?\n",
    "\n",
    "    2. How about keywords that will get a negative weight?\n",
    "\n",
    "    3. What parameter in the perceptron directly affects how many borderline messages end up classified as spam?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<*Please fill in*>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Consider a coin tossing experiment. You toss a coin 100 times, with the result of heads 70 times and tails 30 times. We denote the probability of heads of this coin as Θ. Now consider a coin toss.\n",
    "\n",
    "    1. Build a model using maximum lilkelihood estimation (MLE) to infer Θ.\n",
    "\n",
    "    2. Can we judge that this is an unfair coin? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<*Please fill in*>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. In the programming logistic regression, part (c), we did away with the stochastic idea of SGD and substituted a round-robin version, which deterministically uses the next point in turn to perform the gradient descent. Describe whether you think this is a good robust idea or not for datasets in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<*Please fill in*>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of Individual Work\n",
    "\n",
    "Please initial (between the square brackets) one of the following statements.\n",
    "\n",
    "[ ] I, <*substitute your matric number here*>, certify that I have followed the CS 3244 Machine Learning class guidelines for homework assignments.  In particular, I expressly vow that I have followed the Facebook rule in discussing with others in doing the assignment and did not take notes (digital or printed) from the discussions.  \n",
    "\n",
    "[ ] I, <*substitute your matric number here*>, did not follow the class rules regarding the homework assignment, because of the following reason:\n",
    "\n",
    "<*Please fill in*>\n",
    "\n",
    "I suggest that I should be graded as follows:\n",
    "\n",
    "<*Please fill in*>\n",
    "\n",
    "### References\n",
    "\n",
    "I have refered to the following list of people and websites in preparing my homework submission:\n",
    "\n",
    "<*please fill in*>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
