Question 1:
 
Though we do not normally search for numbers, we should not completely remove these numbers because numbers are 
important when searching for model number, contact number, date etc. Perhaps we can store entries for numbers 
in separate dictionary file and posting file. Normalization of numbers can be done by checking for existence of digit 
in each term by using the `isdigit` method. However, there are still term such as `05p` that is not considered a number. 
Below is the comparison after removing term that contains a) all numbers b) partial numbers

After removing term that consists of all numbers:
	dictionary.txt - 179 KB       dictionary_no_pure_number.txt - 170 KB       
	postings.txt   - 3276 KB      postings_no_pure_number.txt   - 2904 KB
	reduction in space ~ 11.03 %

After removing term that consists of partial numbers:
	dictionary.txt - 179 KB       dictionary_no_number.txt      - 168 KB
	postings.txt   - 3276 KB      postings_no__number.txt       - 2895 KB
	reduction in space ~ 11.35 %

Question 2:

Both the dictionary and postings file will have fewer entries and take up less space.
However, there will not be significant speed improvement for searching.
Find the index of the term in dictionary still takes constant time and getting the postings list from the disk still takes up the same constant disk seek time for all the remaining terms.
The side effect of removing stop words is that the user will not be able to query them or phrase containing the stop words.

Question 3:

By default, both `sent_tokenize` and `word_tokenize` use the PunktTokenizer which 
may split word such as `i.e`, `dr.` or `mr.`. We can add a list of abbreviations
as argument to PunktTokenizer in order to not segment them apart i.e `Dr. House` should 
not return ['Dr.', 'House']. 	
